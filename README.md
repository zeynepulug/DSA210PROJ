# DSA210 TERM PROJECT
## PROJECT OVERVÄ°EW
This project aims to perform a comprehensive analysis of my personal YouTube data, focusing on several key areas, including watch later lists, playlists, subscriptions, comments, search history, and watch history. The purpose is to gain an understanding of my own viewing habits and identify the patterns of it, explore content preferences, and provide insights into how I use the platform over time.

YouTube is the app I use the most in my daily life, making it an ideal choice for this data analysis project. To carry out this analysis, I requested a complete archive of my YouTube data from Google Takeout, a service that allows users to download their data from various Google products. The archive I received contains files in .csv and .html formats, which include detailed records of my interactions with the platform. My dataset includes:

1) Watch Later List: Videos I saved to watch later but may not have viewed yet.
2) Playlists: A collection of curated video playlists, which reflect my content preferences across different themes or topics.
3) Subscriptions: Channels I subscribe to, providing insight into the types of creators and content I engage with.
4) Comments: My interactions and thoughts shared on videos.
5) Search History: Keywords and topics I actively looked up, highlighting my evolving interests over time.
6) Watch History: Videos I have watched, including timestamps, which will help analyze trends in viewing habits (e.g., time of day, duration, recurring themes).
This project aims to answer following questions:
1) What type of content(playlists, channels, or topics) do i engage the most?
2) What are the frequent topics in my search history, and how do they reflect my changing interests?
3) How does my watch history connect to my subscriptions and playlists?
4) What patterns can be identified in my watching behavior, such as frequency, time of day, or duration?
5) Are there any notable changes or patterns in my activities over time?
### Future Work
For the next part of my project I am plannig to follow these steps:

1) Use web scraping to extract relevant data from .html files and convert them into .csv or .json formats.
2) Clean and preprocess .csv files by removing duplicates, inconsistencies, and irrelevant data.
3) Analyze the data using Python libraries Pandas and NumPy.
4) Visualize the results using Matplotlib and Seaborn to create clear and meaningful graphs.
5) Create a final analysis report including all the data analysis
#### Tools to Use:
1) Python
2) Jupyter Notebook
3) Pandas
4) NumPy
5) Matplotlib and Seaborn


